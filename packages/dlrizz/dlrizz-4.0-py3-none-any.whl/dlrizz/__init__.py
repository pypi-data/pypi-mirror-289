def pip():
    print(""" 

Pip Install:
!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib  
"""
    )

def index():
    print(""" 
  
Practical 1:
1) Performing matrix multiplication and finding eigen vectors and eigen values using TensorFlow.

Practical 2:
2) Solving XOR problem using deep feed forward |network.
          
Practical 3:
3) Implementing deep neural network for performing binary classification task.

Practical 4:
4a) Using deep feed forward network with Two Hidden layers for performing Multiclass Classification and predicting the class. 
4b) Using a deep feed forward network with two hidden layers for performing classification and predicting the probability of class.
4c) Using a deep feed forward network with two hidden layers for performing linear regression and predicting values.          
         
Practical 5: 
5a) Evaluating feed forward deep network for regression using KFold cross validation. 
5b) Evaluating feed forward deep network for multiclass Classification using KFold crossvalidation. 
          
Practical 6:
6a) Implementing regularization to avoid overfitting in binary classification 
6b) Implement L2 regularization with alpha=0.001 
6c) Replace L2 regularization with L1 regularization.

Practical 7:
7) Demonstrate recurrent neural network that learns to perform sequence analysis for stock price 
          
Practical 8:          
8) Performing encoding and decoding of images using 8 deep autoencoder. 

Practical 9:          
9) Implementation of convolutional neural network to predict numbers from number images. 

Practical 10:         
10) Denoising of images using autoencoder.       
             
""")
    

def prog(num):
    if num =="1":
        print(""" --- Pract 1 ---
!pip install tensorflow
              
import tensorflow as tf
print("Matrix Multiplication Demo")
x=tf.constant([1,2,3,4,5,6],shape=[2,3])
print(x)
y=tf.constant([7,8,9,10,11,12],shape=[3,2])
print(y)
z=tf.matmul(x,y)
print("Product:",z)
e_matrix_A=tf.random.uniform([2,2],minval=3,maxval=10,dtype=tf.float32,name="matrixA")
print("Matrix A:\\n{}\\n\\n".format(e_matrix_A))
eigen_values_A,eigen_vectors_A=tf.linalg.eigh(e_matrix_A)
print("Eigen Vectors:\\n{}\\n\\nEigen Values:\\n{}\\n".format(eigen_vectors_A,eigen_values_A))



        """)

    elif num =="2":
        print(""" --- Pract 2  ---

pip install numpy
pip install tensorflow
pip install keras
            
import numpy as np
from keras.models import Sequential
from keras.layers import Dense

#create a model
model = Sequential()

# adding layers to the model
model.add(Dense(units = 2, activation = 'relu', input_dim = 2))
model.add(Dense(units = 1, activation = 'sigmoid' ))

#configuration of the model
model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])

# x = inputs and y = output labels (xor TT)
x = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([0,1,1,0])

# get model weights then train
model.get_weights()
model.fit(x,y,epochs = 500)

pred = model.predict(x)
print(pred)


                            
        """)

    elif num =="3":
        print(""" --- Pract 3  ---

!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib  
                                   
from keras.models import Sequential
from keras.layers import Dense
import pandas as pd

names = ["No. of pregnancies","Glucose level","Blood Pressure","skin thickness","Insulin","BMI","Diabetes pedigree","Age","Class"]

df = pd.read_csv ("diabetes.csv")
df.head()

#create model
binaryc = Sequential()

#create layers in the model or NN
binaryc.add(Dense(units=10,activation='relu',input_dim=8))
binaryc.add(Dense(units=8,activation='relu'))
binaryc.add(Dense(units=1,activation='sigmoid'))

binaryc.compile(loss='binary_crossentropy',optimizer='adam',metrics=["accuracy"])

x = df.iloc[:,:-1]
y = df.iloc[:,-1]

from sklearn.model_selection import train_test_split

xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size = 0.25,random_state = 1)

xtrain.shape

ytrain.shape

binaryc.fit(xtrain, ytrain, epochs = 200, batch_size = 20)

predict = binaryc.predict(xtest)
predict.shape

#binary classification
class_label = []

for i in predict:
    if (i >= 0.5):
        class_label.append(1)
    else:
        class_label.append(0)

#print accuracy score
from sklearn.metrics import accuracy_score

print("Accuracy : ", accuracy_score(ytest,class_label))

                            
        """)
    
    elif num =="4a":
        print(""" --- Pract 4a  ---

!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib                

# Cell 1: Import necessary libraries
from keras.models import Sequential
from keras.layers import Dense
from sklearn.datasets import make_blobs
from sklearn.preprocessing import MinMaxScaler
import numpy as np


# Cell 2: Generate synthetic data
X, Y = make_blobs(n_samples=100, centers=2, n_features=2, random_state=1)

# Scale the input features
scalar = MinMaxScaler()
scalar.fit(X)
X = scalar.transform(X)


# Cell 3: Define and compile the model
model = Sequential()
model.add(Dense(4, input_dim=2, activation='relu'))
model.add(Dense(4, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam')


# Cell 4: Train the model
model.fit(X, Y, epochs=400)


# Cell 5: Generate new synthetic data for prediction
X_new, Y_real = make_blobs(n_samples=3, centers=2, n_features=2, random_state=1)
X_new = scalar.transform(X_new)


# Cell 6: Predict and print results
Y_pred = np.round(model.predict(X_new).flatten())
for i in range(len(X_new)):
    print("X=%s, Predicted=%s, Desired=%s" % (X_new[i], Y_pred[i], Y_real[i]))

                            
        """)
    
    elif num =="4b":
        print(""" --- Pract 4b  ---

!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib                

from keras.models import Sequential
from keras.layers import Dense
from sklearn.datasets import make_blobs
from sklearn.preprocessing import MinMaxScaler
import numpy as np


X,Y=make_blobs(n_samples=100,centers=2,n_features=2,random_state=1)
scalar=MinMaxScaler()
scalar.fit(X)
X=scalar.transform(X)
model=Sequential()
model.add(Dense(4,input_dim=2,activation='relu'))
model.add(Dense(4,activation='relu'))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam')
model.fit(X,Y,epochs=400)


# Generate new synthetic data for prediction
X_new, Y_real = make_blobs(n_samples=3, centers=2, n_features=2, random_state=1)
X_new = scalar.transform(X_new)

# Predict and print results
Y_prob = model.predict(X_new).flatten()
Y_class = np.round(Y_prob)
for i in range(len(X_new)):
    print("X=%s, Predicted_probability=%s, Predicted_class=%s" % (X_new[i], Y_prob[i], Y_class[i]))
                            
        """)
    
    elif num =="4c":
        print(""" --- Pract 4c  ---
              
!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib  


from keras.models import Sequential
from keras.layers import Dense
from sklearn.datasets import make_regression
from sklearn.preprocessing import MinMaxScaler

X,Y=make_regression(n_samples=100,n_features=2,noise=0.1,random_state=1)
scalarX,scalarY=MinMaxScaler(),MinMaxScaler()


scalarX.fit(X)
scalarY.fit(Y.reshape(100,1))
X=scalarX.transform(X)
Y=scalarY.transform(Y.reshape(100,1))


model=Sequential()
model.add(Dense(4,input_dim=2,activation='relu'))
model.add(Dense(4,activation='relu'))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='mse',optimizer='adam')
model.fit(X,Y,epochs=1000,verbose=0)


Xnew,a=make_regression(n_samples=3,n_features=2,noise=0.1,random_state=1)
Xnew=scalarX.transform(Xnew)


Ynew=model.predict(Xnew)
for i in range(len(Xnew)):
    print("X=%s,Predicted=%s"%(Xnew[i],Ynew[i]))
                            
        """)
    
    elif num =="5a":
        print(""" --- Pract 5a  ---
#pip install scikeras

# pip install numpy
# pip install pandas
# pip install tensorflow
# pip install keras
# pip install scikit-learn 
# pip install matplotlib  


import pandas as pd
import numpy as np
from sklearn.model_selection import KFold, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from keras.models import Sequential
from keras.layers import Dense
from scikeras.wrappers import KerasRegressor

 
# Load the dataset correctly, skipping the first row (header)
dataframe = pd.read_csv("housing.csv", sep=',', header=0)
print("Shape of dataset:", dataframe.shape)
print("First few rows of dataset:")
print(dataframe.head())
 
# Extract features (X) and target variable (Y)
X = dataframe.drop(columns=['MEDV']).values # Features (all columns except 'MEDV')
Y = dataframe['MEDV'].values              #Target variable ('MEDV')
 
# Check the shape of X (number of features)
print("Shape of X (features):", X.shape)
 
# Define the wider model function
def wider_model():
   model = Sequential()
   model.add(Dense(15,input_dim=X.shape[1], kernel_initializer='normal' , activation='relu'))
   model.add(Dense(13, kernel_initializer='normal', activation='relu'))
   model.add(Dense(1, kernel_initializer='normal'))
   model.compile(loss='mean_squared_error', optimizer='adam')
   return model
 
estimators = []     #Create pipeline with standardization and Keras model
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp',KerasRegressor(build_fn=wider_model, epochs=20, batch_size=5)))
pipeline = Pipeline(estimators)

# Define KFold cross-validation
kfold = KFold(n_splits=10, shuffle=True, random_state=42)


try:                          # Evaluate pipeline using cross-validation
   results = cross_val_score(pipeline, X, Y, cv=kfold)
   print("Wider: %.2f (%.2f) MSE" % (results.mean(), results.std()))
except ValueError as e:
   print("Error during cross-validation:", e)


              

print("Wider: %.2f (%.2f) MSE" % (results.mean(), results.std()))

                            
        """)

    elif num =="5b":
        print(""" --- Pract 5b  ---
              
!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib  
              

# Cell 1
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical
from sklearn.metrics import accuracy_score

              
# Cell 2
# Generate a random multiclass classification dataset
X, y = make_classification(n_samples=100,
                          n_features=20,
                          n_informative=2,
                          n_redundant=0,
                          n_classes=2,
                         n_clusters_per_class=2,
                          random_state=42)

y = to_categorical(y)      # Convert the target variable to categorical format

              
# Cell 3
# Define the k-fold cross-validator
n_splits = 5
kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

model = Sequential()          # Define the feed-forward deep network model
model.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))
model.add(Dense(64, activation='relu'))
model.add(Dense(y.shape[1], activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

fold_accuracies = []            # Perform k-fold cross-validation

              
# Cell 4
for train_index, val_index in kf.split(X):
   X_train, X_val = X[train_index], X[val_index]
   y_train, y_val = y[train_index], y[val_index]
   model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))
   y_pred_prob = model.predict(X_val)
   y_pred = y_pred_prob.argmax(axis=1)  # Get the predicted class index with highest probability
   accuracy = accuracy_score(y_val.argmax(axis=1), y_pred)
   fold_accuracies.append(accuracy)

              
# Cell 5
# Calculate the mean accuracy across all folds
mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)
print(f'Mean accuracy: {mean_accuracy:.2f}')


                            
        """)

    elif num =="6a":
        print(""" --- Pract 6a  ---
              
!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib  

from matplotlib import pyplot
from sklearn.datasets import make_moons
from keras.models import Sequential
from keras.layers import Dense
X,Y=make_moons(n_samples=100,noise=0.2,random_state=1)
n_train=30
trainX,testX=X[:n_train,:],X[n_train:]
trainY,testY=Y[:n_train],Y[n_train:]
#print(trainX)
#print(trainY)
#print(testX)
#print(testY)
model=Sequential()
model.add(Dense(500,input_dim=2,activation='relu'))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
history=model.fit(trainX,trainY,validation_data=(testX,testY),epochs=800)

pyplot.plot(history.history['accuracy'],label='train')
pyplot.plot(history.history['val_accuracy'],label='test')
pyplot.legend()
pyplot.show()
           
                            
        """)

    elif num =="6b":
        print(""" --- Pract 6b  ---
              
!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib  

from matplotlib import pyplot
from sklearn.datasets import make_moons
from keras.models import Sequential
from keras.layers import Dense
from keras.regularizers import l2

X,Y=make_moons(n_samples=100,noise=0.2,random_state=1)
n_train=30
trainX,testX=X[:n_train,:],X[n_train:]
trainY,testY=Y[:n_train],Y[n_train:]
#print(trainX)
#print(trainY)
#print(testX)
#print(testY)
model=Sequential()
model.add(Dense(500,input_dim=2,activation='relu',kernel_regularizer=l2(0.001)))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
history=model.fit(trainX,trainY,validation_data=(testX,testY),epochs=800)

              
pyplot.plot(history.history['accuracy'],label='train')
pyplot.plot(history.history['val_accuracy'],label='test')
pyplot.legend()
pyplot.show()              

                            
        """)

    elif num =="6c":
        print(""" --- Pract 6c  ---
              
!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib  

from matplotlib import pyplot
from sklearn.datasets import make_moons
from keras.models import Sequential
from keras.layers import Dense
from keras.regularizers import l1_l2
X,Y=make_moons(n_samples=100,noise=0.2,random_state=1)
n_train=30
trainX,testX=X[:n_train,:],X[n_train:]
trainY,testY=Y[:n_train],Y[n_train:]
#print(trainX)
#print(trainY)
#print(testX)
#print(testY)
model=Sequential()
model.add(Dense(500,input_dim=2,activation='relu',kernel_regularizer=l1_l2(l1=0.001,l2=0.001)))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
history=model.fit(trainX,trainY,validation_data=(testX,testY),epochs=400)
pyplot.plot(history.history['accuracy'],label='train')
pyplot.plot(history.history['val_accuracy'],label='test')
pyplot.legend()
pyplot.show()

                            
        """)
    
    elif num =="7":
        print(""" --- Pract 7  ---
              
!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib  

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout
from sklearn.preprocessing import MinMaxScaler

# Load training data
dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')
training_set = dataset_train.iloc[:, 1:2].values

# Scale the training data
sc = MinMaxScaler(feature_range=(0, 1))
training_set_scaled = sc.fit_transform(training_set)

# Prepare training data
X_train, Y_train = [], []
for i in range(60, 1258):
    X_train.append(training_set_scaled[i-60:i, 0])
    Y_train.append(training_set_scaled[i, 0])
X_train, Y_train = np.array(X_train), np.array(Y_train)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

# Build the LSTM model
regressor = Sequential()
regressor.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
regressor.add(Dropout(0.2))
regressor.add(LSTM(units=50, return_sequences=True))
regressor.add(Dropout(0.2))
regressor.add(LSTM(units=50, return_sequences=True))
regressor.add(Dropout(0.2))
regressor.add(LSTM(units=50))
regressor.add(Dropout(0.2))
regressor.add(Dense(units=1))
regressor.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
regressor.fit(X_train, Y_train, epochs=50, batch_size=32)

              

# Load test data
dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')
real_stock_price = dataset_test.iloc[:, 1:2].values

# Concatenate training and test data for preprocessing
dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis=0)
inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values
inputs = inputs.reshape(-1, 1)

# Scale the test data
inputs = sc.transform(inputs)

# Prepare test data
X_test = []
for i in range(60, 80):
    X_test.append(inputs[i-60:i, 0])
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Predict stock prices
predicted_stock_price = regressor.predict(X_test)
predicted_stock_price = sc.inverse_transform(predicted_stock_price)

# Plot the results
plt.plot(real_stock_price, color='red', label='Real Google Stock Price')
plt.plot(predicted_stock_price, color='blue', label='Predicted Stock Price')
plt.xlabel('Time')
plt.ylabel('Google Stock Price')
plt.legend()
plt.show()

                            
        """)
    
    elif num =="8":
        print(""" --- Pract 8  ---
              
!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib  


import keras
from keras import layers
from keras.datasets import mnist
import numpy as np

encoding_dim = 32
# This is our input image
input_img = keras.Input(shape=(784,))
# "encoded" is the encoded representation of the input
encoded = layers.Dense(encoding_dim, activation='relu')(input_img)
# "decoded" is the lossy reconstruction of the input
decoded = layers.Dense(784, activation='sigmoid')(encoded)
# Creating autoencoder model
autoencoder = keras.Model(input_img, decoded)
# Create the encoder model
encoder = keras.Model(input_img, encoded)
encoded_input = keras.Input(shape=(encoding_dim,))
# Retrieve the last layer of the autoencoder model
decoder_layer = autoencoder.layers[-1]
# Create the decoder model
decoder = keras.Model(encoded_input, decoder_layer(encoded_input))
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

              
# Scale and make train and test dataset
(X_train, _), (X_test, _) = mnist.load_data()
X_train = X_train.astype('float32') / 255.
X_test = X_test.astype('float32') / 255.
X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))
X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))
print(X_train.shape)
print(X_test.shape)
# Train autoencoder with training dataset
autoencoder.fit(X_train, X_train,
                epochs=50,
                batch_size=256,
                shuffle=True,
                validation_data=(X_test, X_test))

              
encoded_imgs = encoder.predict(X_test)
decoded_imgs = decoder.predict(encoded_imgs)

import matplotlib.pyplot as plt

n = 10  # How many digits we will display
plt.figure(figsize=(40, 4))
for i in range(10):
    # Display original
    ax = plt.subplot(3, 20, i + 1)
    plt.imshow(X_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    
    # Display encoded image
    ax = plt.subplot(3, 20, i + 1 + 20)
    plt.imshow(encoded_imgs[i].reshape(8, 4))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    
    # Display reconstruction
    ax = plt.subplot(3, 20, 2 * 20 + i + 1)
    plt.imshow(decoded_imgs[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

plt.show()

                            
        """)

    elif num =="9":
        print(""" --- Pract 9  ---
              
!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib                


from keras.datasets import mnist
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten
import matplotlib.pyplot as plt

              
# Download MNIST data and split into train and test sets
(X_train, Y_train), (X_test, Y_test) = mnist.load_data()

# Plot the first image in the dataset
plt.imshow(X_train[0])
plt.show()
print(X_train[0].shape)

# Reshape the input data
X_train = X_train.reshape(60000, 28, 28, 1)
X_test = X_test.reshape(10000, 28, 28, 1)

# One-hot encode the labels
Y_train = to_categorical(Y_train)
Y_test = to_categorical(Y_test)
print(Y_train[0])

              
# Create a Sequential model
model = Sequential()

# Add model layers
# Learn image features
model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))
model.add(Conv2D(32, kernel_size=3, activation='relu'))
model.add(Flatten())
model.add(Dense(10, activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=3)

              
# Predict and print the probabilities for the first 4 images in the test set
print(model.predict(X_test[:4]))

# Print the actual labels for comparison
print(Y_test[:4])

                            
        """)
    
    elif num =="10":
        print(""" --- Pract 10  ---
              
!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install keras
!pip install scikit-learn 
!pip install scikeras
!pip install matplotlib  

import keras
from keras.datasets import mnist
from keras import layers
import numpy as np
from keras.callbacks import TensorBoard
import matplotlib.pyplot as plt

              
# Load and preprocess the MNIST dataset
(X_train, _), (X_test, _) = mnist.load_data()
X_train = X_train.astype('float32') / 255.
X_test = X_test.astype('float32') / 255.
X_train = np.reshape(X_train, (len(X_train), 28, 28, 1))
X_test = np.reshape(X_test, (len(X_test), 28, 28, 1))

# Add noise to the images
noise_factor = 0.5
X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)
X_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)

# Clip the noisy images to [0, 1]
X_train_noisy = np.clip(X_train_noisy, 0., 1.)
X_test_noisy = np.clip(X_test_noisy, 0., 1.)

# Visualize some noisy images
n = 10
plt.figure(figsize=(20, 2))
for i in range(1, n + 1):
    ax = plt.subplot(1, n, i)
    plt.imshow(X_test_noisy[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

              
# Build the autoencoder model
input_img = keras.Input(shape=(28, 28, 1))
x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
x = layers.MaxPooling2D((2, 2), padding='same')(x)
x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)
encoded = layers.MaxPooling2D((2, 2), padding='same')(x)
x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)
x = layers.UpSampling2D((2, 2))(x)
x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)
x = layers.UpSampling2D((2, 2))(x)
decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
autoencoder = keras.Model(input_img, decoded)

# Compile the autoencoder model
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Train the autoencoder model
autoencoder.fit(X_train_noisy, X_train, epochs=3, batch_size=128, shuffle=True,
                validation_data=(X_test_noisy, X_test),
                callbacks=[TensorBoard(log_dir='/tmo/tb', histogram_freq=0, write_graph=False)])

              

# Make predictions using the trained autoencoder model
predictions = autoencoder.predict(X_test_noisy)

# Visualize the denoised images
m = 10
plt.figure(figsize=(20, 2))
for i in range(1, m + 1):
    ax = plt.subplot(1, m, i)
    plt.imshow(predictions[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

                            
        """)


   

    else:
        print("Invalid input")

#prog('5b')
        
        