{
    "hub_infer_url": "http://47.97.51.213:8000/v2/models/vllm_model/generate",  // remote service url
    "generate_config": {
        "ignore_eos": true,
        "skip_special_tokens": true,
        "use_beam_search": true,
        "best_of": 3,
        "max_tokens": 127,
        "n": 1,
        "top_k": -1,
        "frequency_penalty": 0.0,
        "length_penalty": 1.0,
        "presence_penalty": 0.0,
        "temperature": 0.0,
        "top_p": 1.0
    }  // inference-related config
}
