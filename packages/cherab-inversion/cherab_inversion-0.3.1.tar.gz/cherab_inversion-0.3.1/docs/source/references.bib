@ARTICLE{Ingesson2008-ve,
  title     = "Chapter 7: Tomography Diagnostics: Bolometry and Soft-{X}-Ray
               Detection",
  author    = "Ingesson, L C and Alper, B and Peterson, B J and Vallet, J-C",
  journal   = "Fusion Sci. Technol.",
  publisher = "Taylor \& Francis",
  volume    =  53,
  number    =  2,
  pages     = "528--576",
  abstract  = "This chapter reviews multichannel broadband measurement of the
               soft-X-ray radiation and total radiation in magnetically confined
               fusion plasma experiments. Common detector types used (including
               bolometers), details of their application, and interpretation of
               their measurements are described. An introduction is given to the
               application of computed tomography methods in the mathematical
               reconstruction of emission profiles from multiple (approximately)
               line-integral measurements, taking into account the specific
               circumstances common in magnetically confined fusion plasma
               experiments. Although the emphasis is on two-dimensional
               tomography of poloidal cross sections, the applications of Abel
               inversion, three-dimensional tomography, vector tomography, and
               other specific methods are briefly discussed. Several examples of
               the application and the plasma parameters that can be derived are
               given.",
  month     =  feb,
  year      =  2008,
  keywords  = "Bolometer; Soft-X-ray detection; Tomography",
  doi       = "10.13182/FST53-528",
  issn      = "1536-1055"
}

@ARTICLE{Hansen2000-zf,
  title    = "The {L}-Curve and its Use in the Numerical Treatment of Inverse
              Problems",
  author   = "Hansen, Per Christian",
  journal  = "in Computational Inverse Problems in Electrocardiology, ed. P.
              Johnston, Advances in Computational Bioengineering",
  volume   =  4,
  pages    = "119--142",
  abstract = "The L-curve is a log-log plot of the norm of a regularized
              solution versus the norm of the corresponding residual norm. It is
              a convenient graphical tool for displaying the trade-off between
              the size of a regularized solution and its fit to the given data,
              as the regularization parameter varies. The L-curve thus gives
              insight into the regularizing properties of the underlying
              regularization method, and it is an aid in choosing an appropriate
              regularization parameter for the given data. In this chapter we
              summarize the main properties of the L-curve, and demonstrate by
              examples its usefulness and its limitations both as an analysis
              tool and as a method for choosing the regularization parameter. 1
              Introduction Practically all regularization methods for computing
              stable solutions to inverse problems involve a trade-off between
              the ``size'' of the regularized solution and the quality of the
              fit that it provides to the given data. What distinguishes the
              various regularization methods is how...",
  year     =  2000,
  keywords = "inverse; l-curve; regularization-parameter-selection"
}

@ARTICLE{Correia2009-xk,
  title    = "Selection of regularization parameter for optical topography",
  author   = "Correia, Teresa and Gibson, Adam and Schweiger, Martin and Hebden,
              Jeremy",
  journal  = "J. Biomed. Opt.",
  volume   =  14,
  number   =  3,
  pages    =  034044,
  abstract = "The choice of the regularization parameter has a profound effect
              on the solution of ill-posed inverse problems such as optical
              topography. We review 11 different methods for selecting the
              Tikhonov regularization parameter that have been described
              previously in the literature. We test them on two trial problems,
              deblurring and optical topography, and conclude that the L-curve
              method is the method of choice, though in particularly ill-posed
              problems, generalized cross-validation may provide an alternative.",
  year     =  2009,
  keywords = "L-curve; Tikhonov; generalized cross validation; inverse problems;
              optical topography; regularization",
  doi      = "10.1117/1.3156839",
  pmid     =  19566336,
  issn     = "1083-3668"
}

@ARTICLE{Xiang2013-sl,
  title    = "Regularization with randomized {SVD} for large-scale discrete
              inverse problems",
  author   = "Xiang, Hua and Zou, Jun",
  journal  = "Inverse Probl.",
  volume   =  29,
  number   =  8,
  pages    = "1--21",
  abstract = "In this paper, we propose an algorithm for solving the large-scale
              discrete ill-conditioned linear problems arising from the
              discretization of linear or nonlinear inverse problems. The
              algorithm combines some existing regularization techniques and
              regularization parameter choice rules with a randomized singular
              value decomposition (SVD), so that only much smaller scale systems
              are needed to solve, instead of the original large-scale
              regularized system. The algorithm can directly apply to some
              existing regularization methods, such as the Tikhonov and
              truncated SVD methods, with some popular regularization parameter
              choice rules such as the L-curve, GCV function, quasi-optimality
              and discrepancy principle. The error of the approximate
              regularized solution is analyzed and the efficiency of the method
              is well demonstrated by the numerical examples. © 2013 IOP
              Publishing Ltd.",
  year     =  2013,
  keywords = "GCV; Inverse problems; L-curve; SVD; TSVD; Tikhonov
              regularization; randomized algorithm",
  doi      = "10.1088/0266-5611/29/8/085008",
  issn     = "0266-5611"
}

@ARTICLE{Anton1996-ik,
  title    = "{X}-ray tomography on the {TCV} tokamak",
  author   = "Anton, M and Weisen, H and Dutch, M J and Von Der Linden, W and
              Buhlmann, F and Chavan, R and Marletaz, B and Marmillod, P and
              Paris, P",
  journal  = "Plasma Phys. Controlled Fusion",
  volume   =  38,
  number   =  11,
  pages    = "1849--1878",
  abstract = "The TCV tokamak offers outstanding variability of the plasma
              shape. Using x-ray tomography, the shape of the inner flux
              surfaces of a poloidal cross section of the plasma can be
              reconstructed, including fast variations due to MHD activity. Both
              the hardware and the software of the 200 channel system developed
              for TCV are described. A new 'dynamical' calibration takes actual
              plasma parameters into account to determine the spectrum-dependent
              detector efficiency, resulting in an enhanced quality of
              reconstructions. Tomographic inversions are obtained using a
              variety of methods such as maximum entropy, linear regularization
              and a newly developed method based on the Fisher information. The
              merits of the different algorithms, which have been implemented as
              MATLAB functions, are compared. Inversion results are analysed
              with the help of singular-value decomposition, allowing, for
              example, identification of MHD modes without using any a priori
              information on the poloidal mode structure. Recent results on the
              dependence of sawtooth activity on the plasma triangularity are
              presented to demonstrate the performance of the soft x-ray
              tomography system. © 1996 IOP Publishing Ltd.",
  year     =  1996,
  doi      = "10.1088/0741-3335/38/11/001",
  issn     = "0741-3335"
}

@ARTICLE{Odstrcil2016-va,
  title    = "Optimized tomography methods for plasma emissivity reconstruction
              at the {ASDEX} Upgrade tokamak",
  author   = "Odstrčil, T and Pütterich, T and Odstrčil, M and Gude, A and
              Igochine, V and Stroth, U",
  journal  = "Rev. Sci. Instrum.",
  volume   =  87,
  number   =  12,
  pages    =  123505,
  abstract = "The soft X-ray (SXR) emission provides valuable insight into
              processes happening inside of high-temperature plasmas. A standard
              method for deriving the local emissivity profiles of the plasma
              from the line-of-sight integrals measured by pinhole cameras is
              the tomographic inversion. Such an inversion is challenging due to
              its ill-conditioned nature and because the reconstructed profiles
              depend not only on the quality of the measurements but also on the
              inversion algorithm used. This paper provides a detailed
              description of several tomography algorithms, which solve the
              inversion problem of Tikhonov regularization with linear
              computational complexity in the number of basis functions. The
              feasibility of combining these methods with the minimum Fisher
              information regularization is demonstrated, and various
              statistical methods for the optimal choice of the regularization
              parameter are investigated with emphasis on their reliability and
              robustness. Finally, the accuracy and the capability of the
              methods are demonstrated by reconstructions of experimental SXR
              profiles, featuring poloidal asymmetric impurity distributions as
              measured at the ASDEX Upgrade tokamak.",
  year     =  2016,
  doi      = "10.1063/1.4971367",
  issn     = "0034-6748,1089-7623"
}

@ARTICLE{Odstrcil2012-ta,
  title     = "Modern numerical methods for plasma tomography optimisation",
  author    = "Odstrcil, M and Mlynar, J and Odstrcil, T and Alper, B and
               Murari, A",
  journal   = "Nucl. Instrum. Methods Phys. Res. A",
  publisher = "Elsevier",
  volume    =  686,
  pages     = "156--161",
  abstract  = "Tomography is a technique which is widely applied to fusion
               plasmas as it can provide improved understanding of plasma
               emissivity distributions. It is challenging because of the sparse
               nature of data available from the measured plasma projections. An
               optimised version of robust and fast tomographic algorithm based
               on the Tikhonov regularisation constrained to Minimum Fisher
               Information is presented in this contribution. A new
               regularisation matrix enforcing preferential emissivity
               smoothness along magnetic flux surfaces is introduced. The paper
               also details application of advanced numerical methods which lead
               to a substantial decrease in computation time. Subsequent
               implementation of fast presolvers of the inverse problem further
               contributes to the algorithms efficiency and also an improved
               stability of the tomography reconstruction. Finally, reliability
               and performance of the tomography algorithm is exemplified by the
               reconstruction of soft X-ray data evolution following tungsten
               ablation into a JET plasma. The resulting speed of reconstruction
               is compared to other referenced tomographic algorithms. © 2012
               Elsevier B.V. All rights reserved.",
  year      =  2012,
  keywords  = "Fusion plasmas; Imaging; MFI; Soft X-rays; Tokamak; Tomography",
  doi       = "10.1016/j.nima.2012.05.063",
  issn      = "0168-9002"
}

@ARTICLE{Hansen1992-pf,
  title    = "Analysis of Discrete Ill-Posed Problems by Means of the {L}-Curve",
  author   = "Hansen, Per Christian",
  journal  = "SIAM Rev.",
  volume   =  34,
  number   =  4,
  pages    = "561--580",
  abstract = "When discrete ill-posed problems are analyzed and solved by
              various numerical regularization techniques, a very convenient way
              to display information about the regularized solution is to plot
              the norm or seminorm of the solution versus the norm of the
              residual vector. In particular, the graph associated with Tikhonov
              regularization plays a central role. The main purpose of this
              paper is to advocate the use of this graph in the numerical
              treatment of discrete ill-posed problems. The graph is
              characterized quantitatively, and several important relations
              between regularized solutions and the graph are derived. It is
              also demonstrated that several methods choosing for the
              regularization parameter are related to locating a characteristic
              L-shaped ``corner'' of the graph",
  year     =  1992,
  keywords = "discrete ill-posed problems; generalized SVD; least squares;
              regularization",
  doi      = "10.1137/1034115",
  issn     = "0036-1445"
}

@ARTICLE{Reginska2012-dh,
  title     = "A Regularization Parameter in Discrete Ill-Posed Problems",
  author    = "Regińska, Teresa",
  journal   = "SIAM Journal on Scientific Computing",
  publisher = "Society for Industrial and Applied Mathematics",
  abstract  = "The Tikhonov regularization method for discrete ill-posed
               problems is considered. For the practical choice of the
               regularization parameter $\alpha$, some authors use a plot of the
               norm of the regularized solution versus the norm of the residual
               vector for all $\alpha$ considered. This paper contains an
               analysis of the shape of this plot and gives a theoretical
               justification for choosing the regularization parameter so it is
               related to the ``L-corner'' of the plot considered in the
               logarithmic scale. Moreover, a new criterion for choosing
               $\alpha$ is introduced (independent of the shape of the plot)
               which gives a new interpretation of the ``corner criterion''
               mentioned above. The existence of ``L-corner'' is discussed.",
  month     =  feb,
  year      =  2012,
  doi       = "10.1137/S1064827593252672",
  language  = "en"
}

@ARTICLE{Golub1979-gf,
  title     = "Generalized Cross-Validation as a Method for Choosing a Good
               Ridge Parameter",
  author    = "Golub, Gene H and Heath, Michael and Wahba, Grace",
  journal   = "Technometrics",
  publisher = "Taylor \& Francis",
  volume    =  21,
  number    =  2,
  pages     = "215--223",
  abstract  = "Consider the ridge estimate (?) for ? in the model unknown, (?) =
               (X T X + n?I)?1 X T y. We study the method of generalized
               cross-validation (GCV) for choosing a good value for ? from the
               data. The estimate is the minimizer of V(?) given by where A(?) =
               X(X T X + n?I)?1 X T . This estimate is a rotation-invariant
               version of Allen's PRESS, or ordinary cross-validation. This
               estimate behaves like a risk improvement estimator, but does not
               require an estimate of σ2, so can be used when n ? p is small, or
               even if p ≥ 2 n in certain cases. The GCV method can also be used
               in subset selection and singular value truncation methods for
               regression, and even to choose from among mixtures of these
               methods.",
  month     =  may,
  year      =  1979,
  doi       = "10.1080/00401706.1979.10489751",
  issn      = "0040-1706"
}

@ARTICLE{Phillips1962-pk,
  title     = "A Technique for the Numerical Solution of Certain Integral
               Equations of the First Kind",
  author    = "Phillips, David L",
  journal   = "J. ACM",
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  volume    =  9,
  number    =  1,
  pages     = "84--97",
  month     =  jan,
  year      =  1962,
  doi       = "10.1145/321105.321114",
  issn      = "0004-5411"
}

@ARTICLE{Allen1974-bu,
  title     = "The Relationship Between Variable Selection and Data Agumentation
               and a Method for Prediction",
  author    = "Allen, David M",
  journal   = "Technometrics",
  publisher = "Taylor \& Francis",
  volume    =  16,
  number    =  1,
  pages     = "125--127",
  abstract  = "We show that data augmentation provides a rather general
               formulation for the study of biased prediction techniques using
               multiple linear regression. Variable selection is a limiting
               case, and Ridge regression is a special case of data
               augmentation. We propose a way to obtain predictors given a
               credible criterion of good prediction.",
  month     =  feb,
  year      =  1974,
  doi       = "10.1080/00401706.1974.10489157",
  issn      = "0040-1706"
}
